---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)


Sys.setenv("GBIFDB_HOME"=tempdir())
Sys.setenv("GBIFDB_DB"=tempdir())

```

# gbifdb

<!-- badges: start -->
<!-- badges: end -->

The goal of `gbifdb` is to provide a relational database interface to a `parquet` based serializations of `gbif` data. 
Instead of requiring custom functions for filtering and selecting data from the central GBIF server (as in `rgbif`), `gbifdb` users can take advantage of the full array of `dplyr` and `tidyr` functions which can be automatically translated to SQL by `dbplyr`.
Users already familiar with SQL can construct SQL queries directly with `DBI` instead. 
`gbifdb` sends these queries to [`duckdb`](https://duckdb.org), a high-performance, columnar-oriented database engine which runs entirely inside the client,
(unlike server-client databases such as MySQL or Postgres, no additional setup is needed outside of installing `gbifdb`.)
`duckdb` is able to execute these SQL queries directly on-disk against the Parquet data files, side-stepping limitations of available RAM or the need to import the data. 
It's highly optimized implementation can be faster even than in-memory operations in `dplyr`, especially when using fast SSD-based storage disks.
Unlike the `arrow` R packae interface, which can also query `parquet` files, `duckdb` supports the full set of SQL instructions, including windowed operations like `group_by`+`summarise` as well as table joins.


## Installation

**NOTE**: `gbifdb` currently requires the dev version of `duckdb`, which you can install using:

```r
install.packages("https://github.com/duckdb/duckdb/releases/download/master-builds/duckdb_r_src.tar.gz", repos = NULL)
```


You can install the released version of `gbifdb` from [CRAN](https://CRAN.R-project.org) with:

``` r
install.packages("gbifdb")
```

And the development version from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("cboettig/gbifdb")
```

`gbifdb` has few dependencies: only `duckdb` and `DBI` are required.  

## Getting Started

```{r}
library(gbifdb)
library(dplyr)  # optional, for dplyr-based operations
library(aws.s3) # optional, for S3-based sync
```

Before you can use `gbifdb` you will need to download GBIF data.
Alternatively, many users may choose to launch an RStudio-server instance on a cloud platform that already has a local copy of the GBIF data available. 


```{r}
gbif_download(dir = gbif_dir())
```

Simply point `gbif_conn()` at the directory containing your parquet files to initialize a connection.

```{r}
import_ebird(tar)
```


Once the data have been downloaded and imported successfully, a user can access the full ebird record quite quickly:

```{r}  
df <- ebird()
df
```

Now, we can use `dplyr` to perform standard queries:

```{r}
colnames(df)
```

```{r}
df %>% count(`SCIENTIFIC NAME`, sort=TRUE)
```



```{r include=FALSE}
Sys.unsetenv("GBIFDB_HOME")
Sys.unsetenv("GBIFDB_DB")

```


